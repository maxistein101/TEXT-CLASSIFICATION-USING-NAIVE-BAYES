{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b315a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44517e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99333\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "names_of_directory = [\"alt.atheism\",\"comp.graphics\",\"comp.os.ms-windows.misc\",\"comp.sys.ibm.pc.hardware\",\"comp.sys.mac.hardware\",\"comp.windows.x\",\"misc.forsale\",\"rec.autos\",\"rec.motorcycles\",\"rec.sport.baseball\",\"rec.sport.hockey\",\"sci.crypt\",\"sci.electronics\",\"sci.med\",\"sci.space\",\"soc.religion.christian\",\"talk.politics.guns\",\"talk.politics.mideast\",\"talk.politics.misc\",\"talk.religion.misc\"]\n",
    "words = {}\n",
    "file = open(\"Stop_words.txt\")\n",
    "f = file.read()\n",
    "stop_words = f.split(\"\\n\")\n",
    "stop_words = set(stop_words)\n",
    "def read_file(path):\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                if word in stop_words:\n",
    "                    continue\n",
    "                if(words.get(word,0)==0):\n",
    "                    words[word]=1\n",
    "                else:\n",
    "                    words[word]+=1\n",
    "j=0\n",
    "for path_extension in names_of_directory:\n",
    "    path = \"C:\\\\Users\\\\Masood\\\\Ackerman\\\\Mini_newspaper\\\\mini_newsgroups\\\\\" + path_extension\n",
    "    os.chdir(path)\n",
    "    l = os.listdir()\n",
    "    for i in l:\n",
    "        file_path = f\"{path}\\{i}\"\n",
    "        j+=1\n",
    "        read_file(file_path)\n",
    "os.chdir(r\"C:\\Users\\Masood\\Ackerman\")\n",
    "print(len(words.keys()))\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a3e0c",
   "metadata": {},
   "source": [
    "                           *SORTING DICTIONARY BY VALUES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51076e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.axis import Axis\n",
    "words_new = {}\n",
    "x = np.arange(len(words.keys()))\n",
    "plt.plot(x,words.values())\n",
    "\n",
    "plt.show()\n",
    "words = {k:v for k,v in sorted(words.items(),key = lambda key_value:key_value[1],reverse = True)}\n",
    "cnt=0\n",
    "for i in words:\n",
    "    if(cnt>4000):\n",
    "        break\n",
    "    words_new[i] = words[i]\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884d11d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(len(words_new.keys()))\n",
    "col = list(words_new.keys())\n",
    "x = np.zeros((2000,len(words_new.keys())))\n",
    "X = pd.DataFrame(x,columns = col)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b22c656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['I', '>', 'The', 'From:', 'Subject:', 'Date:', 'Newsgroups:',\n",
      "       'Message-ID:', 'Path:', 'Lines:',\n",
      "       ...\n",
      "       'key,', 'limits', '(Gordon', 'SIMMS', 'upset', 'dept.', 'condition,',\n",
      "       'inner', 'adapter', 'ports'],\n",
      "      dtype='object', length=4001)\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "output=0\n",
    "Y = []\n",
    "def read_file(path):\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                if word in X.columns:\n",
    "                    X.loc[j][word]+=1\n",
    "        Y.append(output)\n",
    "                \n",
    "                \n",
    "\n",
    "for path_extension in names_of_directory:\n",
    "    path = \"C:\\\\Users\\\\Masood\\\\Ackerman\\\\Mini_newspaper\\\\mini_newsgroups\\\\\" + path_extension\n",
    "    os.chdir(path)\n",
    "    l = os.listdir()\n",
    "    for i in l:\n",
    "        file_path = f\"{path}\\{i}\"\n",
    "        read_file(file_path)\n",
    "        j+=1\n",
    "    output+=1\n",
    "os.chdir(r\"C:\\Users\\Masood\\Ackerman\")\n",
    "Y = np.array(Y)\n",
    "print(X.columns)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dae5252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  0  0  0  0  0  1  0  3  0  0  0  0  0  0  0  1  0  0  2]\n",
      " [ 0  9  1  4  2  0  2  0  2  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 22  5  0  0  3  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 16  1  0  3  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  3 19  0  1  0  0  1  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  2  3  2  1 17  2  0  0  0  0  0  0  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  1  0 19  0  0  0  1  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  3 20  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 19  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1 19  3  0  0  0  1  1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  1  2  1  1 12  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  1  0  1  0  3  0  2  0  0 19  0  0  0  0  0  1  0  1]\n",
      " [ 0  0  3  5  1  0  2  1  4  1  0  0  6  0  1  0  1  0  0  0]\n",
      " [ 0  0  1  0  1  0  1  1  2  0  0  0  1 17  0  0  0  0  1  0]\n",
      " [ 1  0  0  1  0  0  0  1  0  0  0  0  1  1 23  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 22  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  0  0  0  0  0  1  0  1  0 14  1  0  3]\n",
      " [ 0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  2 18  2  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  5  2 12  2]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  4  0  1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76        31\n",
      "           1       0.75      0.43      0.55        21\n",
      "           2       0.67      0.69      0.68        32\n",
      "           3       0.41      0.73      0.52        22\n",
      "           4       0.68      0.73      0.70        26\n",
      "           5       0.94      0.59      0.72        29\n",
      "           6       0.43      0.83      0.57        23\n",
      "           7       0.80      0.80      0.80        25\n",
      "           8       0.51      0.95      0.67        20\n",
      "           9       0.76      0.76      0.76        25\n",
      "          10       0.75      0.60      0.67        20\n",
      "          11       1.00      0.68      0.81        28\n",
      "          12       0.67      0.24      0.35        25\n",
      "          13       0.89      0.68      0.77        25\n",
      "          14       0.79      0.77      0.78        30\n",
      "          15       0.85      0.92      0.88        24\n",
      "          16       0.44      0.61      0.51        23\n",
      "          17       0.82      0.75      0.78        24\n",
      "          18       0.75      0.52      0.62        23\n",
      "          19       0.53      0.42      0.47        24\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.71      0.67      0.67       500\n",
      "weighted avg       0.72      0.67      0.67       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state=0)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pre = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(Y_test,Y_pre))\n",
    "print(classification_report(Y_test,Y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a676e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train,Y_train):\n",
    "    result = {}\n",
    "    classes = set(Y_train)\n",
    "    result[\"total_data\"] = len(Y_train)\n",
    "    for curr_class in classes:\n",
    "        result[curr_class] = {}\n",
    "        X_train_new = X_train[Y_train==curr_class]\n",
    "        result[curr_class][\"total_words\"] = X_train_new.sum()\n",
    "        result[curr_class][\"total_count\"] = len(Y_train[Y_train==curr_class])\n",
    "        feature_number = X_train.shape[1]\n",
    "        for curr_feature in range(1,feature_number+1):\n",
    "            result[curr_class][curr_feature] = X_train_new[:,curr_feature-1].sum()\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c41558e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(result,x,ai):\n",
    "    \n",
    "    p_ai = np.log(result[ai][\"total_count\"]) - np.log(result[\"total_data\"])\n",
    "    total_words = len(x)\n",
    "    curr_word = 1\n",
    "    for word in x:\n",
    "        curr_prob = word*(np.log((result[ai][curr_word]) + 1) - np.log((result[ai][\"total_words\"]) + total_words))\n",
    "        p_ai+=curr_prob\n",
    "        curr_word+=1\n",
    "    return p_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25947d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictSinglePoint(result,x):\n",
    "    classes = result.keys()\n",
    "    best_p = -100000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    \n",
    "    for curr_class in classes:\n",
    "        if(curr_class==\"total_data\"):\n",
    "            continue\n",
    "        curr_probability = probability(result,x,curr_class)\n",
    "        if(first_run or best_p<curr_probability):\n",
    "            best_p = curr_probability\n",
    "            best_class = curr_class\n",
    "            first_run = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07a4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(result, X_test):\n",
    "    Y_pred = []\n",
    "    for x in X_test:\n",
    "        x_class = PredictSinglePoint(result,x)\n",
    "        Y_pred.append(x_class)\n",
    "    Y_pred = np.array(Y_pred)\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45437901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(Y_pre,Y_test):\n",
    "    count=0\n",
    "    \n",
    "    for i in range(len(Y_pre)):\n",
    "        if(Y_pre[i]==Y_test[i]):\n",
    "            count+=1\n",
    "    return count/len(Y_pre)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de496474",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66d38522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  0  0  0  0  0  1  0  3  0  0  0  0  0  0  0  1  0  0  2]\n",
      " [ 0  9  1  4  2  0  2  0  2  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 22  5  0  0  3  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 16  1  0  3  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  3 19  0  1  0  0  1  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  2  3  2  1 17  2  0  0  0  0  0  0  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  1  0 19  0  0  0  1  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  3 20  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 19  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1 19  3  0  0  0  1  1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  1  2  1  1 12  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  1  0  1  0  3  0  2  0  0 19  0  0  0  0  0  1  0  1]\n",
      " [ 0  0  3  5  1  0  2  1  4  1  0  0  6  0  1  0  1  0  0  0]\n",
      " [ 0  0  1  0  1  0  1  1  2  0  0  0  1 17  0  0  0  0  1  0]\n",
      " [ 1  0  0  1  0  0  0  1  0  0  0  0  1  1 23  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 22  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  0  0  0  0  0  1  0  1  0 14  1  0  3]\n",
      " [ 0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  2 18  2  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  5  2 12  2]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  4  0  1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76        31\n",
      "           1       0.75      0.43      0.55        21\n",
      "           2       0.67      0.69      0.68        32\n",
      "           3       0.41      0.73      0.52        22\n",
      "           4       0.68      0.73      0.70        26\n",
      "           5       0.94      0.59      0.72        29\n",
      "           6       0.43      0.83      0.57        23\n",
      "           7       0.80      0.80      0.80        25\n",
      "           8       0.51      0.95      0.67        20\n",
      "           9       0.76      0.76      0.76        25\n",
      "          10       0.75      0.60      0.67        20\n",
      "          11       1.00      0.68      0.81        28\n",
      "          12       0.67      0.24      0.35        25\n",
      "          13       0.89      0.68      0.77        25\n",
      "          14       0.79      0.77      0.78        30\n",
      "          15       0.85      0.92      0.88        24\n",
      "          16       0.44      0.61      0.51        23\n",
      "          17       0.82      0.75      0.78        24\n",
      "          18       0.75      0.52      0.62        23\n",
      "          19       0.53      0.42      0.47        24\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.71      0.67      0.67       500\n",
      "weighted avg       0.72      0.67      0.67       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pre_bruh = predict(result,X_test)\n",
    "print(confusion_matrix(Y_test,Y_pre_bruh))\n",
    "print(classification_report(Y_test,Y_pre_bruh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b6450f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of our NB :  0.674\n",
      "Score of inbuilt classifier :  0.674\n"
     ]
    }
   ],
   "source": [
    "print(\"Score of our NB : \",score(Y_pre_bruh,Y_test))\n",
    "print(\"Score of inbuilt classifier : \",clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8824a1",
   "metadata": {},
   "source": [
    "                       ALSO DOING COMPARISON WITH LOGISTIC REGRESSION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1b25672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  3]\n",
      " [ 0 16  0  1  0  0  0  0  0  0  0  1  2  0  0  0  0  0  0  1]\n",
      " [ 1  3 23  2  1  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 18  0  1  1  0  1  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  2 19  0  2  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  0  0  0  1 27  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0 20  0  0  0  1  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  2 21  0  0  0  0  1  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  1  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0 21  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  3  0  0  0  0 21  0  0  0  0  0  0  0  3]\n",
      " [ 0  1  0  1  0  0  1  0  0  0  0  0 20  0  1  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  0  2  0  0  0  0  0 20  0  0  0  0  1  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  2 26  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 24  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  1  0  2  0  0 13  0  1  5]\n",
      " [ 0  0  1  0  0  1  0  0  0  0  0  1  0  0  0  0  2 18  1  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  1  0  1  0  0  0  0  3  0 13  4]\n",
      " [ 3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  6 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        31\n",
      "           1       0.76      0.76      0.76        21\n",
      "           2       0.92      0.72      0.81        32\n",
      "           3       0.72      0.82      0.77        22\n",
      "           4       0.83      0.73      0.78        26\n",
      "           5       0.90      0.93      0.92        29\n",
      "           6       0.62      0.87      0.73        23\n",
      "           7       0.81      0.84      0.82        25\n",
      "           8       0.90      0.95      0.93        20\n",
      "           9       0.95      0.84      0.89        25\n",
      "          10       0.86      0.95      0.90        20\n",
      "          11       0.81      0.75      0.78        28\n",
      "          12       0.83      0.80      0.82        25\n",
      "          13       0.83      0.80      0.82        25\n",
      "          14       0.96      0.87      0.91        30\n",
      "          15       1.00      1.00      1.00        24\n",
      "          16       0.62      0.57      0.59        23\n",
      "          17       1.00      0.75      0.86        24\n",
      "          18       0.52      0.57      0.54        23\n",
      "          19       0.39      0.54      0.46        24\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.81      0.80      0.80       500\n",
      "weighted avg       0.81      0.80      0.80       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state=0)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pre = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(Y_test,Y_pre))\n",
    "print(classification_report(Y_test,Y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f28b79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "n_cpu = os.cpu_count()\n",
    "print(n_cpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
